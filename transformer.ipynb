{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：The Annotated Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    '''\n",
    "    A standard Encoder-Decoder architecture. Base for this and many\n",
    "    other models.\n",
    "    '''\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        # 编码属于transformer的一部分，不应该由其他函数的外部传入\n",
    "        # 在这里构造嵌入，是为了外部更好的替换嵌入，且放置在上层api中，降低学习者的学习负担\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "    \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        return self.decode(self.encode(src,src_mask), src_mask, tgt, tgt_mask)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        # src的形状是[batch_size, seq_len]，每个值代表一个词的索引\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    # 完成最后的线性变换，将模型输出转换为词汇表的概率分布\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"产生N个完全相同的网络层\"\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 自定义LayerNorm\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        # 定义两个可学习的参数，可能还会使用到pytorch的广播机制\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        # 防止分母为0\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 在最后一个维度上求均值和方差\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        # 在最后一个维度求标准差\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"完整的Encoder包含N层\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"每一层的输入是x和mask\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # 采用了回调函数的编程方法\n",
    "    def forward(self, x, sublayer):\n",
    "        # 进行层归一化后再通过注意力机制和前馈神经网络，然后再进行残差连接\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        # 需要两个残差连接和层归一化\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        # layer.size是dimension\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        # 最后补上一个LayerNorm\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        # 带掩码的自注意力机制\n",
    "        self.self_attn = self_attn\n",
    "        # 注意力机制\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        # 一个block有三个残差连接和层归一化，比encoder多一个\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        # x是decoder的输出，作为query，memory是encoder的输出，作为key和value\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        # 最后一个是前馈神经网络\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于单层decoder中的self-attention子层，我们需要使用mask机制，以防止在当前位置关注到后面的位置。\n",
    "# 这段代码用于创建一个掩码，屏蔽掉后续的位置。它的主要功能是生成一个上三角矩阵，其中 k=1 指定了从主对角线以上的部分为 1，其他部分为 0。\n",
    "def subsequent_mask(size):\n",
    "    # 一般size是序列的长度\n",
    "    attn_shape = (1, size, size)\n",
    "    # np.triu返回矩阵的上三角部分，k=0表示将主对角线和以上位置置为1，k=1表示将主对角线以上的位置置为1\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    # 获得embedding的维度\n",
    "    d_k = query.size(-1)\n",
    "    # transpose是为了将最后两个维度交换，这样才能进行矩阵乘法\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        # mask是一个上三角矩阵，将mask为0的位置的分数置为负无穷\n",
    "        # mask的维度是[1,1,tgt_len,tgt_len],先计算Q和K的乘积，然后mask掉无效的位置\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    # TODO 为什么要返回p_attn，这是因为在decoder中的src_attn中，我们需要将p_attn返回，以便于后续的可视化\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        # linears是一个list，包含四个线性层,主要是为了得到Q,K,V\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            # 假设 mask 是一个形状为 (batch_size, seq_length) 的张量，使用 unsqueeze(1) 后，形状将变为 (batch_size, 1, seq_length)\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        # transpose可以使用permute来代替\n",
    "        # 这里只会进行三次的线性变换\n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        # contiguous 是 PyTorch 中的一个方法，用于返回一个连续内存中的张量副本。\n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在transformer中，前馈神经网络是一个全连接的神经网络，包含两个线性变换和一个激活函数，他在每一个块的多头注意力机制之后进行残差连接和层归一化之后调用，而且做完\n",
    "# 前馈神经网络之后还要进行残差连接和层归一化\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    # 输入相同的维度，输出相同的维度，但是中间的维度可以不同 \n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    # vocab是词表的大小，d_model是embedding的维度\n",
    "    # nn.Embedding是一个简单的查找表，用于存储每一个词的embedding，我们可以通过索引来查找对应的embedding\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以看到，我们在编写一个架构的时候，会将每个子结构使用nn.Module进行封装，然后在forward函数中调用这些子结构，这样可以使得代码更加清晰，同时也方便了后续的调用和复用\n",
    "# p_{k,2i}=\\sin\\left(k/1000^{2i/d}\\right)  k是位置，i是维度，d是embedding的维度\n",
    "class PositionalEncoding(nn.Module):\n",
    "    # max_len是最大编码长度，默认是5000\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # dropout是为了防止过拟合\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        # 提前计算位置编码可以减少训练时间和提高推理速度\n",
    "\n",
    "        # pe是一个二维矩阵，第一维是位置，第二维是embedding的维度，即每一行是一个位置的embedding\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        # 生成一个表示一个位置的列表\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        # 生成比例因子\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        # 使用了切片操作，将偶数列的位置编码计算sin，奇数列的位置编码计算cos\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # unsqueeze是为了增加一个维度，这样可以和embedding相加(batch_size,seq_len,d_model)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        # 将pe注册为一个buffer，这样在保存模型的时候，pe不会被保存\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 将位置编码加到embedding上\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_vocab和tgt_vocab是源语言和目标语言的词表大小, N是encoder和decoder的层数，d_model是embedding的维度，d_ff是前馈神经网络的维度，h是多头注意力机制的头数\n",
    "# 如果是机器翻译任务，src_vocab和tgt_vocab的大小是不一样的\n",
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    # 提供一个深拷贝的方法\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            # 第一个维度是batch_size，第二个维度是序列长度\n",
    "            # 去掉最后一个词（通常用于训练时输入解码器的序列）。\n",
    "            self.trg = trg[:, :-1]\n",
    "            # 去掉第一个词。模型要预测的就是从第二个词开始的序列。\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = \\\n",
    "                self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "\n",
    "            # trg.size(): torch.Size([30, 9])\n",
    "            # trg_mask.size(): torch.Size([30, 9, 9])\n",
    "            # ntokens: tensor(270)\n",
    "    \n",
    "    # 只有定义为静态方法，才能在init中调用\n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        # 对每一个句子，生成一个上三角矩阵，unsqueeze(-2）在倒数第二个维度上增加一个维度\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        # subsequent_mask需要传入一个序列的长度，返回一个0上三角矩阵\n",
    "        # 由于广播机制，那么tgt_mask的第二个维度会被扩展为tgt.size(-1)，即序列的长度，返回的subsequent_mask也会进行广播\n",
    "        tgt_mask = tgt_mask & Variable(\n",
    "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        return tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行一个epoch，一个epoch包含多个batch,一般会将所有数据都遍历一遍\n",
    "def run_epoch(data_iter, model, loss_compute):\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(batch.src, batch.trg, \n",
    "                            batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        if i % 50 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
    "                    (i, loss / batch.ntokens, tokens / elapsed))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "    return total_loss / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于动态调整批次大小（batch size）\n",
    "# max_src_in_batch：当前批次中源序列（源语言）的最大长度，max_tgt_in_batch：当前批次中目标序列（目标语言）的最大长度\n",
    "# 在该文件中这个函数没有用到\n",
    "global max_src_in_batch, max_tgt_in_batch\n",
    "def batch_size_fn(new, count, sofar):\n",
    "    global max_src_in_batch, max_tgt_in_batch\n",
    "    if count == 1:\n",
    "        max_src_in_batch = 0\n",
    "        max_tgt_in_batch = 0\n",
    "    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n",
    "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n",
    "    src_elements = count * max_src_in_batch\n",
    "    tgt_elements = count * max_tgt_in_batch\n",
    "    return max(src_elements, tgt_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顶一个了学习率调度器\n",
    "class NoamOpt:\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        # 实际使用的优化器，\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        # 预热参数\n",
    "        self.warmup = warmup\n",
    "        # 一个调节学习率的乘数系数。这个值用于放大或缩小学习率的大小。\n",
    "        self.factor = factor\n",
    "        # 模型的维度大小\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "\n",
    "    # 每次调用step函数，学习率都会更新，并且步数+1，参数也会更新    \n",
    "    def step(self):\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        # 将学习率应用到优化器的参数组中 \n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "\n",
    "    # 负责计算学习率，基于当前的步数和预设参数。\n",
    "    def rate(self, step = None):\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "\n",
    "\n",
    "# 为了方便使用，我们定义了一个函数，该函数接受模型作为输入，并返回一个NoamOpt实例。\n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    # size：类别数量，表示有多少个可能的分类。\n",
    "    # padding_idx：填充索引，用于标识输入序列中的填充部分（特别是在自然语言处理任务中），这些部分不会被用于计算损失。\n",
    "    # smoothing：平滑因子，控制标签平滑的强度，通常是一个小的值（如 0.1）。平滑因子越大，目标分布越“平滑”。\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        # 使用KLDivLoss作为损失函数，size_average=False表示不对损失求平均\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        # 表示目标类别的分布中给目标类别赋予的概率\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        # 初始化一个用于存储平滑后的真实分布的变量。\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        # x：模型的输出（通常是 log-softmax 的结果），形状为 [batch_size, num_classes]，表示每\n",
    "        # target：真实的目标标签（通常是整数编码的类别），形状为 [batch_size]，表示每个样本的真实类别。\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        # 将所有元素置为平滑因子除以类别数量\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        # 将属于填充部分的部分的损失置为0，注意一行表示所有的类别，所以肯定包含了填充的类别\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        # 返回目标类别向量中填充部分的索引\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            # 在批次的维度将padding的位置置为0\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Example of label smoothing.\n",
    "crit = LabelSmoothing(5, 0, 0.4)\n",
    "predict = torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0],\n",
    "                             [0, 0.2, 0.7, 0.1, 0], \n",
    "                             [0, 0.2, 0.7, 0.1, 0]])\n",
    "v = crit(Variable(predict.log()), \n",
    "         Variable(torch.LongTensor([2, 1, 0])))\n",
    "\n",
    "# Show the target distributions expected by the system.\n",
    "plt.imshow(crit.true_dist)\n",
    "None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.1333, 0.6000, 0.1333, 0.1333],\n",
      "        [0.0000, 0.6000, 0.1333, 0.1333, 0.1333],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(crit.true_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fabd18b84f0>]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crit = LabelSmoothing(5, 0, 0.1)\n",
    "def loss(x):\n",
    "    d = x + 3 * 1\n",
    "    predict = torch.FloatTensor([[0, x / d, 1 / d, 1 / d, 1 / d],\n",
    "                                 ])\n",
    "    return crit(Variable(predict.log()),\n",
    "                 Variable(torch.LongTensor([1]))).item()\n",
    "\n",
    "y = [loss(x) for x in range(1, 100)]\n",
    "x = np.arange(1, 100)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V：词汇表的大小（Vocabulary size），即在数据中每个元素的取值范围为 [1, V-1]。batch：每个批次（batch）中的样本数量。nbatches：生成的批次数量，即迭代的次数。\n",
    "# data_gen(V, 30, 20)\n",
    "def data_gen(V, batch, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task.\"\n",
    "    for i in range(nbatches):\n",
    "        # randint(low, high, size)：生成一个 [low, high) 范围内的整数，size 表示生成的随机数的形状。\n",
    "        data = torch.from_numpy(np.random.randint(1, V, size=(batch, 10)))\n",
    "        data[:, 0] = 1\n",
    "        # src和tgt是相同的数据，即输入和输出是一样的\n",
    "        src = Variable(data, requires_grad=False)\n",
    "        tgt = Variable(data, requires_grad=False)\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n",
    "                              y.contiguous().view(-1)) / norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        # item函数是将一个标量Tensor转换为一个Python number\n",
    "        return loss.item() * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_359/3025647527.py:22: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 3.249415 Tokens per Sec: 1616.934448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 1.886713 Tokens per Sec: 2028.311523\n",
      "tensor(1.8641)\n",
      "Epoch Step: 1 Loss: 2.047898 Tokens per Sec: 1629.618896\n",
      "Epoch Step: 1 Loss: 1.630408 Tokens per Sec: 1988.877808\n",
      "tensor(1.6358)\n",
      "Epoch Step: 1 Loss: 1.831577 Tokens per Sec: 1615.190918\n",
      "Epoch Step: 1 Loss: 1.438090 Tokens per Sec: 2005.948242\n",
      "tensor(1.4386)\n",
      "Epoch Step: 1 Loss: 1.683892 Tokens per Sec: 1633.069824\n",
      "Epoch Step: 1 Loss: 1.356744 Tokens per Sec: 2031.285645\n",
      "tensor(1.3682)\n",
      "Epoch Step: 1 Loss: 1.378142 Tokens per Sec: 1624.564697\n",
      "Epoch Step: 1 Loss: 0.947862 Tokens per Sec: 2021.448730\n",
      "tensor(0.9829)\n",
      "Epoch Step: 1 Loss: 1.063265 Tokens per Sec: 1641.388550\n",
      "Epoch Step: 1 Loss: 0.535661 Tokens per Sec: 2051.201172\n",
      "tensor(0.5472)\n",
      "Epoch Step: 1 Loss: 0.779421 Tokens per Sec: 1683.699341\n",
      "Epoch Step: 1 Loss: 0.295361 Tokens per Sec: 2027.429077\n",
      "tensor(0.2977)\n",
      "Epoch Step: 1 Loss: 0.541436 Tokens per Sec: 1668.306152\n",
      "Epoch Step: 1 Loss: 0.177185 Tokens per Sec: 1957.155518\n",
      "tensor(0.2211)\n",
      "Epoch Step: 1 Loss: 0.666337 Tokens per Sec: 1665.859497\n",
      "Epoch Step: 1 Loss: 0.245399 Tokens per Sec: 2079.520264\n",
      "tensor(0.2918)\n",
      "Epoch Step: 1 Loss: 0.863170 Tokens per Sec: 1677.232056\n",
      "Epoch Step: 1 Loss: 0.583371 Tokens per Sec: 2043.690552\n",
      "tensor(0.5439)\n"
     ]
    }
   ],
   "source": [
    "# Train the simple copy task.\n",
    "V = 11\n",
    "criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "model = make_model(V, V, N=2)\n",
    "model_opt = NoamOpt(model.src_embed[0].d_model, 1, 400,\n",
    "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n",
    "for epoch in range(10):\n",
    "    # train会将所有子模块的training属性设置为True\n",
    "    model.train()\n",
    "    run_epoch(data_gen(V, 30, 20), model, \n",
    "              SimpleLossCompute(model.generator, criterion, model_opt))\n",
    "    model.eval()\n",
    "    print(run_epoch(data_gen(V, 30, 5), model, \n",
    "                    SimpleLossCompute(model.generator, criterion, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  3,  5,  7,  8, 10, 10]])\n"
     ]
    }
   ],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask, \n",
    "                           Variable(ys), \n",
    "                           Variable(subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys\n",
    "\n",
    "model.eval()\n",
    "src = Variable(torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]]) )\n",
    "src_mask = Variable(torch.ones(1, 1, 10) )\n",
    "print(greedy_decode(model, src, src_mask, max_len=10, start_symbol=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
